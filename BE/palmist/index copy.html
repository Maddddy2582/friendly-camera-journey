<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Voice Assistant</title>
    <link
      rel="stylesheet"
      href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"
    />
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.13/dist/bundle.min.js"></script>
    <script type="module">
      import { interpolateInferno } from "https://cdn.skypack.dev/d3-scale-chromatic@3";
      let socket;
let audioContext;
let audioQueue = [];
let isPlaying = false;

async function connectWebSocket() {
  socket = new WebSocket("ws://localhost:8000/ws");

  socket.onopen = () => {
    console.log("WebSocket connection established");
    document.getElementById("indicator").innerHTML = `<span style="color:green">CONNECTED</span>`;
    initAudioContext();
  };

  socket.onmessage = async (event) => {
  if (typeof event.data === "string") {
    try {
      const message = JSON.parse(event.data);
      console.log("Text Message:", message);
    } catch (error) {
      console.error("Error parsing JSON:", error);
    }
  } else if (event.data instanceof Blob) {
    // Handle Binary Audio Blob
    console.log("Binary audio blob received:", event.data.size, "bytes");
    const arrayBuffer = await event.data.arrayBuffer();
    const audioBuffer = decodePCM16ArrayBuffer(arrayBuffer);
    if (audioBuffer) {
      audioQueue.push(audioBuffer);
      playAudioStream();
    }
  } else {
    console.warn("Unsupported message type:", event.data);
  }
};


  socket.onerror = (error) => {
    console.error("WebSocket error:", error);
    document.getElementById("indicator").innerHTML = `<span style="color:red">ERROR</span>`;
  };

  socket.onclose = () => {
    console.warn("WebSocket connection closed");
    document.getElementById("indicator").innerHTML = `<span style="color:red">DISCONNECTED</span>`;
  };
}

function initAudioContext() {
  if (!audioContext) {
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
  }
}

function decodePCM16ArrayBuffer(arrayBuffer) {
  try {
    const view = new DataView(arrayBuffer);
    const numSamples = view.byteLength / 2; // 16-bit PCM -> 2 bytes per sample

    const audioBuffer = audioContext.createBuffer(
      1, // Mono audio
      numSamples, // Number of samples
      16000 // Sample rate (adjust as per server configuration)
    );

    const channelData = audioBuffer.getChannelData(0);
    for (let i = 0; i < numSamples; i++) {
      const sample = view.getInt16(i * 2, true) / 32768.0; // Normalize PCM16
      channelData[i] = sample;
    }

    return audioBuffer;
  } catch (error) {
    console.error("Failed to decode PCM16 ArrayBuffer:", error);
    return null;
  }
}


// Play Audio Stream from Queue

function playAudioStream() {
  if (isPlaying || audioQueue.length === 0) return;

  isPlaying = true;
  const audioBuffer = audioQueue.shift();

  const sourceNode = audioContext.createBufferSource();
  sourceNode.buffer = audioBuffer;
  sourceNode.connect(audioContext.destination);

  sourceNode.onended = () => {
    isPlaying = false;
    playAudioStream(); // Play the next chunk if available
  };

  sourceNode.start();
  console.log("Playing audio chunk");
}


async function sendAudioToServer(wavBuffer) {
  try {
    const audioBase64 = btoa(
      new Uint8Array(wavBuffer)
        .reduce((data, byte) => data + String.fromCharCode(byte), "")
    );

    const message = {
      type: "audio",
      content: audioBase64,
    };

    socket.send(JSON.stringify(message));
    console.log("Audio sent to server");
  } catch (error) {
    console.error("Error sending audio to server:", error);
  }
}
function resetAudioPlayer() {
  audioQueue = [];
  isPlaying = false;
  console.log("Audio player reset on speech start");
}


async function main() {
  await connectWebSocket();

  const myvad = await vad.MicVAD.new({
    positiveSpeechThreshold: 0.85,
    minSpeechFrames: 3,
    preSpeechPadFrames: 5,
    negativeSpeechThreshold: 0.4,
    onFrameProcessed: (probs) => {
      const indicatorColor = interpolateInferno(probs.isSpeech / 2);
      document.body.style.setProperty("--indicator-color", indicatorColor);
    },
    onSpeechStart: () => {
      console.log("Speech start detected");
      resetAudioPlayer(); // Clear the audio queue and reset playback
    },
    onSpeechEnd: async (audio) => {
      console.log("Speech end detected");
      const wavBuffer = vad.utils.encodeWAV(audio);
      await sendAudioToServer(wavBuffer);
    },
  });

  window.myvad = myvad;

  window.toggleVAD = () => {
    if (myvad.listening === false) {
      myvad.start();
      document.getElementById("toggle_vad_button").textContent = "STOP";
      document.getElementById("indicator").textContent = "running";
    } else {
      myvad.pause();
      document.getElementById("toggle_vad_button").textContent = "START VAD";
      document.getElementById("indicator").innerHTML = `<span style="color:red">stopped</span>`;
      const indicatorColor = interpolateInferno(0);
      document.body.style.setProperty("--indicator-color", indicatorColor);
    }
  };

  window.toggleVAD();
  document.getElementById("toggle_vad_button").disabled = false;
}

main();


    </script>
  </head>
  <style>
    html {
      box-sizing: border-box;
    }
    *,
    *::after,
    *::before {
      box-sizing: inherit;
    }
    body {
      --indicator-color: black;
      background: radial-gradient(black 55%, var(--indicator-color));
      min-height: 100vh;
      color: white;
      margin: 0;
    }
    h1 {
      font-weight: bold;
      color: #fff;
      font-size: 16pt;
    }
    .content {
      padding-inline: 20px;
      margin-inline: auto;
      padding-top: 20px;
    }
    @media (min-width: 1250px) {
      .content {
        padding-top: 100px;
        width: 800px;
        padding-inline: 0;
      }
    }

    #playlist {
      max-height: 400px;
      overflow-y: scroll;
      list-style: none;
      padding-left: 0;
    }
    #playlist li:hover {
      background-color: rgba(100, 100, 100, 0.33);
    }
    #playlist li:first-child {
      border-left: 2px blue solid;
    }
    #playlist li {
      max-height: 0;
      opacity: 0;
      animation: grow 1s ease-in-out forwards;
      padding-left: 5px;
    }
    button {
      background-color: black;
      border: white 1px solid;
      color: white;
    }
    button:hover {
      color: red;
      border-color: red;
    }
    @keyframes grow {
      to {
        max-height: 100px;
        opacity: 1;
      }
    }
    .control-row {
      display: flex;
      justify-content: space-between;
    }
    .header {
      display: flex;
      justify-content: flex-end;
    }
    .github-icon {
      color: white;
      text-decoration: none;
    }
    .github-icon:hover {
      color: red;
      text-decoration: none;
    }
  </style>
  <body>
    <div class="content-container">
      <div class="content">
        <h1>Voice Assistant Demo</h1>
        <div class="control-row">
          <div id="indicator">
            <span style="color: red">LOADING</span>
          </div>
          <button id="toggle_vad_button" onclick="window.toggleVAD()" disabled>
            START
          </button>
        </div>
        <ol id="playlist" reversed></ol>
      </div>
    </div>
  </body>
</html>
